# -*- coding: utf-8 -*-
"""IamProTask.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lR-O-tFuh-hgkZzm_HCmiCQ8FAIc2WxI

# **Classification by Ethnicity project**

Import libraries
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report, confusion_matrix

"""Create Deep learning model"""

# Create the CNN model
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224,224,3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(5, activation='softmax'))  # 5 output classes

# Compile the model
model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

model.summary()

"""Model Taining"""

batch_size = 32
# Train the model
history = model.fit(
    traindata,
    steps_per_epoch=traindata.samples // traindata.batch_size,
    epochs=10,
    validationsteps=validationdata.samples // validationdata.batch_size
)

"""Model Evaluation"""

# Evaluate the model on the test set
test_loss, test_acc = model.evaluate(testdata)
print('Test accuracy:', test_acc)

# Make predictions on the test set
y_pred = model.predict(testdata)
y_pred_classes = y_pred.argmax(axis=1)
true_labels = testdata.classes

# Generate classification report and confusion matrix
print(classification_report(true_labels, y_pred_classes))
print(confusion_matrix(true_labels, y_pred_classes))